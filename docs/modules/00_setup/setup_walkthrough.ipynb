{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup Walkthrough: Getting Your Environment Ready\n",
    "\n",
    "Welcome! This notebook will guide you through setting up your development environment for building transformers.\n",
    "\n",
    "## What We'll Do\n",
    "\n",
    "1. ‚úì Verify Python version (3.11+)\n",
    "2. ‚úì Install PyTorch with appropriate backend (CUDA/MPS/CPU)\n",
    "3. ‚úì Install course dependencies\n",
    "4. ‚úì Test your setup with example code\n",
    "5. ‚úì Run environment validation\n",
    "\n",
    "**Estimated time:** 15-20 minutes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Verify Python Version\n",
    "\n",
    "We require Python 3.11 or higher for this course."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "print(f\"Python version: {sys.version}\")\n",
    "print(f\"Version info: {sys.version_info}\")\n",
    "\n",
    "# Check minimum version\n",
    "if sys.version_info >= (3, 11):\n",
    "    print(\"\\n‚úì Python version is compatible!\")\n",
    "else:\n",
    "    print(\"\\n‚ùå Please upgrade to Python 3.11 or higher\")\n",
    "    print(\"   Visit: https://www.python.org/downloads/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Check Platform and Available Hardware\n",
    "\n",
    "Let's see what hardware you have available for training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import platform\n",
    "\n",
    "print(f\"Operating System: {platform.system()}\")\n",
    "print(f\"Platform: {platform.platform()}\")\n",
    "print(f\"Processor: {platform.processor()}\")\n",
    "print(f\"Architecture: {platform.machine()}\")\n",
    "\n",
    "# Platform-specific info\n",
    "if platform.system() == \"Darwin\":  # macOS\n",
    "    print(\"\\nRunning on macOS - we'll use Metal Performance Shaders (MPS) if available\")\n",
    "elif platform.system() == \"Linux\":\n",
    "    print(\"\\nRunning on Linux - we'll check for CUDA GPUs\")\n",
    "elif platform.system() == \"Windows\":\n",
    "    print(\"\\nRunning on Windows - we'll check for CUDA GPUs\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Install PyTorch\n",
    "\n",
    "**Before running this cell**, you should install PyTorch from the command line:\n",
    "\n",
    "### macOS (Apple Silicon - M1/M2/M3/M4)\n",
    "```bash\n",
    "pip install torch torchvision torchaudio\n",
    "```\n",
    "\n",
    "### Linux/Windows with NVIDIA GPU\n",
    "Visit [pytorch.org](https://pytorch.org/get-started/locally/) and use their selector.\n",
    "\n",
    "### CPU-only (any platform)\n",
    "```bash\n",
    "pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cpu\n",
    "```\n",
    "\n",
    "After installing, run this cell to verify:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    import torch\n",
    "    print(f\"‚úì PyTorch version: {torch.__version__}\")\n",
    "    print(f\"  Built with CUDA: {torch.cuda.is_available()}\")\n",
    "    \n",
    "    # Check for CUDA\n",
    "    if torch.cuda.is_available():\n",
    "        print(f\"  CUDA version: {torch.version.cuda}\")\n",
    "        print(f\"  GPU devices: {torch.cuda.device_count()}\")\n",
    "        print(f\"  GPU 0: {torch.cuda.get_device_name(0)}\")\n",
    "    \n",
    "    # Check for MPS (Apple Silicon)\n",
    "    if hasattr(torch.backends, 'mps'):\n",
    "        print(f\"  MPS available: {torch.backends.mps.is_available()}\")\n",
    "        if torch.backends.mps.is_available():\n",
    "            print(\"  ‚úì Metal Performance Shaders (MPS) enabled!\")\n",
    "    \n",
    "    # Determine device\n",
    "    if torch.cuda.is_available():\n",
    "        device = torch.device(\"cuda\")\n",
    "        print(f\"\\n‚úì Will use device: CUDA (GPU)\")\n",
    "    elif hasattr(torch.backends, 'mps') and torch.backends.mps.is_available():\n",
    "        device = torch.device(\"mps\")\n",
    "        print(f\"\\n‚úì Will use device: MPS (Apple Silicon GPU)\")\n",
    "    else:\n",
    "        device = torch.device(\"cpu\")\n",
    "        print(f\"\\n‚úì Will use device: CPU\")\n",
    "    \n",
    "    print(f\"\\nDevice set to: {device}\")\n",
    "    \n",
    "except ImportError:\n",
    "    print(\"‚ùå PyTorch not installed!\")\n",
    "    print(\"   Please install PyTorch following the instructions above.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Install Course Dependencies\n",
    "\n",
    "Install all required packages from the project root:\n",
    "\n",
    "```bash\n",
    "# From the project root directory\n",
    "pip install -e .\n",
    "```\n",
    "\n",
    "Or using make:\n",
    "```bash\n",
    "make install\n",
    "```\n",
    "\n",
    "After installing, verify the installation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test imports\n",
    "print(\"Testing imports...\\n\")\n",
    "\n",
    "try:\n",
    "    import tiny_transformer\n",
    "    print(f\"‚úì tiny_transformer version: {tiny_transformer.__version__}\")\n",
    "except ImportError as e:\n",
    "    print(f\"‚ùå Failed to import tiny_transformer: {e}\")\n",
    "\n",
    "try:\n",
    "    from tiny_transformer import attention\n",
    "    print(\"‚úì attention module imported\")\n",
    "except ImportError as e:\n",
    "    print(f\"‚ùå Failed to import attention: {e}\")\n",
    "\n",
    "try:\n",
    "    from tiny_transformer.utils import check_shape, plot_attention_pattern\n",
    "    print(\"‚úì utils module imported\")\n",
    "except ImportError as e:\n",
    "    print(f\"‚ùå Failed to import utils: {e}\")\n",
    "\n",
    "try:\n",
    "    import numpy as np\n",
    "    print(f\"‚úì numpy version: {np.__version__}\")\n",
    "except ImportError:\n",
    "    print(\"‚ùå numpy not installed\")\n",
    "\n",
    "try:\n",
    "    import matplotlib\n",
    "    print(f\"‚úì matplotlib version: {matplotlib.__version__}\")\n",
    "except ImportError:\n",
    "    print(\"‚ùå matplotlib not installed\")\n",
    "\n",
    "print(\"\\nAll core dependencies are installed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Test Your Setup with Example Code\n",
    "\n",
    "Let's run a simple attention mechanism to verify everything works!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from tiny_transformer.attention import scaled_dot_product_attention\n",
    "\n",
    "# Determine device\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "elif hasattr(torch.backends, 'mps') and torch.backends.mps.is_available():\n",
    "    device = torch.device(\"mps\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "\n",
    "print(f\"Running on device: {device}\\n\")\n",
    "\n",
    "# Create sample inputs\n",
    "batch_size = 2\n",
    "seq_len = 4\n",
    "d_k = 8\n",
    "\n",
    "q = torch.randn(batch_size, seq_len, d_k, device=device)\n",
    "k = torch.randn(batch_size, seq_len, d_k, device=device)\n",
    "v = torch.randn(batch_size, seq_len, d_k, device=device)\n",
    "\n",
    "print(f\"Query shape: {q.shape}\")\n",
    "print(f\"Key shape: {k.shape}\")\n",
    "print(f\"Value shape: {v.shape}\")\n",
    "\n",
    "# Run attention\n",
    "output, attention_weights = scaled_dot_product_attention(q, k, v)\n",
    "\n",
    "print(f\"\\nOutput shape: {output.shape}\")\n",
    "print(f\"Attention weights shape: {attention_weights.shape}\")\n",
    "\n",
    "# Verify attention weights sum to 1\n",
    "attn_sum = attention_weights.sum(dim=-1)\n",
    "print(f\"\\nAttention weights sum (should be ~1.0): {attn_sum[0, 0].item():.6f}\")\n",
    "\n",
    "print(\"\\n‚úì Attention mechanism working correctly!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Run Environment Validation Tool\n",
    "\n",
    "Our project includes a comprehensive validation tool. Run it from the command line:\n",
    "\n",
    "```bash\n",
    "make verify\n",
    "```\n",
    "\n",
    "Or directly:\n",
    "```bash\n",
    "python tools/verify_environment.py\n",
    "```\n",
    "\n",
    "You can also run it from this notebook:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run verification tool\n",
    "import subprocess\n",
    "import sys\n",
    "\n",
    "result = subprocess.run(\n",
    "    [sys.executable, \"../../../tools/verify_environment.py\"],\n",
    "    capture_output=True,\n",
    "    text=True\n",
    ")\n",
    "\n",
    "print(result.stdout)\n",
    "if result.stderr:\n",
    "    print(\"Errors:\", result.stderr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7: Run Test Suite\n",
    "\n",
    "Let's verify the existing test suite passes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run pytest on the attention module\n",
    "result = subprocess.run(\n",
    "    [sys.executable, \"-m\", \"pytest\", \"../../../tests/test_attention.py\", \"-v\"],\n",
    "    capture_output=True,\n",
    "    text=True\n",
    ")\n",
    "\n",
    "print(result.stdout)\n",
    "if result.stderr:\n",
    "    print(\"Errors:\", result.stderr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 8: Quick Visualization Test\n",
    "\n",
    "Let's test our visualization utilities:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from tiny_transformer.utils import plot_attention_pattern\n",
    "\n",
    "# Create sample attention pattern\n",
    "batch_size = 1\n",
    "seq_len = 8\n",
    "d_k = 16\n",
    "\n",
    "q = torch.randn(batch_size, seq_len, d_k)\n",
    "k = torch.randn(batch_size, seq_len, d_k)\n",
    "v = torch.randn(batch_size, seq_len, d_k)\n",
    "\n",
    "output, attention_weights = scaled_dot_product_attention(q, k, v)\n",
    "\n",
    "# Plot\n",
    "plot_attention_pattern(\n",
    "    attention_weights[0],  # First batch\n",
    "    title=\"Sample Attention Pattern\"\n",
    ")\n",
    "plt.show()\n",
    "\n",
    "print(\"‚úì Visualization working!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Success Criteria\n",
    "\n",
    "You're ready to move forward if:\n",
    "\n",
    "- [ ] Python 3.11+ is installed\n",
    "- [ ] PyTorch is installed and working on your device (CUDA/MPS/CPU)\n",
    "- [ ] All course dependencies imported successfully\n",
    "- [ ] Attention mechanism example runs without errors\n",
    "- [ ] Verification tool passes all checks\n",
    "- [ ] Test suite passes\n",
    "- [ ] Visualization displays correctly\n",
    "\n",
    "If all checks pass: **üéâ Congratulations! Your environment is ready!**\n",
    "\n",
    "## Troubleshooting\n",
    "\n",
    "### PyTorch Installation Issues\n",
    "- For macOS: Make sure you're using the latest pip version: `pip install --upgrade pip`\n",
    "- For CUDA: Visit pytorch.org and use their installation selector\n",
    "- For CPU-only: Use the `--index-url` flag as shown above\n",
    "\n",
    "### Import Errors\n",
    "- Make sure you ran `pip install -e .` from the project root\n",
    "- Check you're in the correct Python environment (virtual environment)\n",
    "- Try: `pip install -e . --force-reinstall`\n",
    "\n",
    "### Test Failures\n",
    "- Some tests may fail if PyTorch isn't installed correctly\n",
    "- Check the error messages carefully - they usually indicate what's wrong\n",
    "\n",
    "## Next Steps\n",
    "\n",
    "1. ‚úì Read `shape_debugging_primer.md` to master shape debugging\n",
    "2. ‚úì (Optional) Review `pytorch_refresher.ipynb` if you need PyTorch review\n",
    "3. ‚úì Move on to Module 01: Attention Mechanism\n",
    "\n",
    "**You're all set! Happy learning!**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
