{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PyTorch Refresher: Essential Concepts for Transformers\n",
    "\n",
    "This notebook reviews PyTorch fundamentals you'll need for building transformers. If you're already comfortable with PyTorch, you can skim or skip this.\n",
    "\n",
    "## Topics Covered\n",
    "\n",
    "1. Tensor creation and operations\n",
    "2. Broadcasting and shapes\n",
    "3. Matrix operations (crucial for attention!)\n",
    "4. Autograd and gradients\n",
    "5. Building with `nn.Module`\n",
    "6. Forward and backward passes\n",
    "7. Parameter management\n",
    "\n",
    "**Estimated time:** 45 minutes\n",
    "\n",
    "Let's begin!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "\n",
    "# Set device\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "elif hasattr(torch.backends, 'mps') and torch.backends.mps.is_available():\n",
    "    device = torch.device(\"mps\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Tensor Creation and Basic Operations\n",
    "\n",
    "Tensors are the fundamental data structure in PyTorch - think of them as multi-dimensional arrays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating tensors\n",
    "a = torch.tensor([1, 2, 3])  # From list\n",
    "b = torch.zeros(3, 4)         # All zeros\n",
    "c = torch.ones(2, 3)          # All ones\n",
    "d = torch.randn(2, 3)         # Random normal distribution\n",
    "e = torch.arange(0, 10, 2)    # Range with step\n",
    "\n",
    "print(\"Tensor from list:\", a)\n",
    "print(\"\\nZeros (3x4):\\n\", b)\n",
    "print(\"\\nOnes (2x3):\\n\", c)\n",
    "print(\"\\nRandom normal (2x3):\\n\", d)\n",
    "print(\"\\nRange [0, 10) step 2:\", e)\n",
    "\n",
    "# Tensor properties\n",
    "print(f\"\\nShape: {d.shape}\")\n",
    "print(f\"Dimensions: {d.dim()}\")\n",
    "print(f\"Data type: {d.dtype}\")\n",
    "print(f\"Device: {d.device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating Tensors for Transformers\n",
    "\n",
    "In transformers, we typically work with 3D tensors: `(batch_size, sequence_length, dimension)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Typical transformer tensor shapes\n",
    "batch_size = 8\n",
    "seq_len = 128\n",
    "d_model = 512\n",
    "\n",
    "# Random embeddings\n",
    "embeddings = torch.randn(batch_size, seq_len, d_model)\n",
    "\n",
    "print(f\"Embeddings shape: {embeddings.shape}\")\n",
    "print(f\"  Batch size: {embeddings.size(0)}\")\n",
    "print(f\"  Sequence length: {embeddings.size(1)}\")\n",
    "print(f\"  Model dimension: {embeddings.size(2)}\")\n",
    "\n",
    "# Alternative indexing (negative indices)\n",
    "print(f\"\\nUsing negative indexing:\")\n",
    "print(f\"  Last dimension (d_model): {embeddings.size(-1)}\")\n",
    "print(f\"  Second to last (seq_len): {embeddings.size(-2)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Broadcasting and Shape Manipulation\n",
    "\n",
    "Broadcasting allows operations on tensors of different shapes. This is crucial for transformers!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Broadcasting examples\n",
    "x = torch.randn(3, 4)\n",
    "y = torch.randn(4)  # Note: different shape!\n",
    "\n",
    "# Broadcasting: (3, 4) + (4,) → (3, 4)\n",
    "z = x + y\n",
    "print(f\"x shape: {x.shape}\")\n",
    "print(f\"y shape: {y.shape}\")\n",
    "print(f\"x + y shape: {z.shape}\")\n",
    "print(f\"\\nBroadcasting worked! y was expanded to (3, 4)\\n\")\n",
    "\n",
    "# Common reshape operations\n",
    "a = torch.randn(2, 3, 4)\n",
    "print(f\"Original shape: {a.shape}\")\n",
    "\n",
    "# View (reshape)\n",
    "b = a.view(2, 12)  # Flatten last two dimensions\n",
    "print(f\"After view(2, 12): {b.shape}\")\n",
    "\n",
    "# Unsqueeze (add dimension)\n",
    "c = a.unsqueeze(0)  # Add batch dimension at position 0\n",
    "print(f\"After unsqueeze(0): {c.shape}\")\n",
    "\n",
    "# Squeeze (remove dimension of size 1)\n",
    "d = c.squeeze(0)  # Remove dimension 0 (size 1)\n",
    "print(f\"After squeeze(0): {d.shape}\")\n",
    "\n",
    "# Transpose\n",
    "e = a.transpose(1, 2)  # Swap dimensions 1 and 2\n",
    "print(f\"After transpose(1, 2): {e.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Critical: Transpose for Attention\n",
    "\n",
    "The most important operation in attention is transposing the key matrix!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulating Q @ K^T in attention\n",
    "batch_size = 2\n",
    "seq_len = 4\n",
    "d_k = 8\n",
    "\n",
    "Q = torch.randn(batch_size, seq_len, d_k)\n",
    "K = torch.randn(batch_size, seq_len, d_k)\n",
    "\n",
    "print(f\"Q shape: {Q.shape}  (batch, seq_len, d_k)\")\n",
    "print(f\"K shape: {K.shape}  (batch, seq_len, d_k)\")\n",
    "\n",
    "# Transpose last two dimensions of K\n",
    "K_T = K.transpose(-2, -1)  # Or K.transpose(1, 2)\n",
    "print(f\"K^T shape: {K_T.shape}  (batch, d_k, seq_len)\")\n",
    "\n",
    "# Compute Q @ K^T\n",
    "scores = Q @ K_T  # @ is matrix multiplication\n",
    "print(f\"Q @ K^T shape: {scores.shape}  (batch, seq_len, seq_len)\")\n",
    "\n",
    "print(\"\\n✓ This creates the attention score matrix!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Matrix Operations\n",
    "\n",
    "Matrix multiplication is the core of transformers. Let's master it!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Matrix multiplication operators\n",
    "A = torch.randn(3, 4)\n",
    "B = torch.randn(4, 5)\n",
    "\n",
    "# Three ways to do matrix multiplication\n",
    "C1 = torch.matmul(A, B)\n",
    "C2 = A @ B  # Preferred!\n",
    "C3 = torch.mm(A, B)  # Only works for 2D\n",
    "\n",
    "print(f\"A shape: {A.shape}\")\n",
    "print(f\"B shape: {B.shape}\")\n",
    "print(f\"A @ B shape: {C2.shape}\")\n",
    "\n",
    "# Batched matrix multiplication\n",
    "A_batch = torch.randn(8, 3, 4)  # 8 batches of (3x4) matrices\n",
    "B_batch = torch.randn(8, 4, 5)  # 8 batches of (4x5) matrices\n",
    "\n",
    "C_batch = A_batch @ B_batch  # Batched: (8, 3, 4) @ (8, 4, 5) = (8, 3, 5)\n",
    "print(f\"\\nBatched matmul: {A_batch.shape} @ {B_batch.shape} = {C_batch.shape}\")\n",
    "\n",
    "# Element-wise multiplication (NOT matrix multiplication!)\n",
    "D = torch.randn(3, 4)\n",
    "E = torch.randn(3, 4)\n",
    "F = D * E  # Element-wise (Hadamard product)\n",
    "print(f\"\\nElement-wise: {D.shape} * {E.shape} = {F.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Autograd: Automatic Differentiation\n",
    "\n",
    "PyTorch automatically computes gradients for backpropagation. This is what makes training possible!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enable gradient tracking\n",
    "x = torch.tensor([2.0], requires_grad=True)\n",
    "print(f\"x: {x}\")\n",
    "print(f\"Requires grad: {x.requires_grad}\")\n",
    "\n",
    "# Forward pass: compute y = x^2\n",
    "y = x ** 2\n",
    "print(f\"\\ny = x^2: {y}\")\n",
    "\n",
    "# Backward pass: compute dy/dx\n",
    "y.backward()\n",
    "print(f\"\\nGradient dy/dx: {x.grad}\")\n",
    "print(f\"Expected: 2*x = 2*2 = 4 ✓\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### More Complex Example: Simple Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create parameters\n",
    "W = torch.randn(3, 4, requires_grad=True)\n",
    "b = torch.randn(4, requires_grad=True)\n",
    "x = torch.randn(2, 3)  # Input (batch_size=2, input_dim=3)\n",
    "\n",
    "# Forward pass: y = x @ W + b\n",
    "y = x @ W + b  # (2, 3) @ (3, 4) = (2, 4)\n",
    "print(f\"Output shape: {y.shape}\")\n",
    "\n",
    "# Compute a simple loss (mean)\n",
    "loss = y.mean()\n",
    "print(f\"Loss: {loss.item()}\")\n",
    "\n",
    "# Backward pass\n",
    "loss.backward()\n",
    "\n",
    "# Check gradients\n",
    "print(f\"\\nW.grad shape: {W.grad.shape}\")\n",
    "print(f\"b.grad shape: {b.grad.shape}\")\n",
    "print(\"\\n✓ Gradients computed automatically!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Building with nn.Module\n",
    "\n",
    "`nn.Module` is the base class for all neural network modules. You'll use this constantly!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple linear layer example\n",
    "class SimpleLinear(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim):\n",
    "        super().__init__()\n",
    "        # Define parameters\n",
    "        self.weight = nn.Parameter(torch.randn(input_dim, output_dim))\n",
    "        self.bias = nn.Parameter(torch.randn(output_dim))\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # x: (batch_size, input_dim)\n",
    "        return x @ self.weight + self.bias  # (batch_size, output_dim)\n",
    "\n",
    "# Create and test\n",
    "layer = SimpleLinear(input_dim=10, output_dim=5)\n",
    "x = torch.randn(32, 10)  # Batch of 32 examples\n",
    "output = layer(x)  # Calls forward() automatically\n",
    "\n",
    "print(f\"Input shape: {x.shape}\")\n",
    "print(f\"Output shape: {output.shape}\")\n",
    "print(f\"\\nParameters:\")\n",
    "for name, param in layer.named_parameters():\n",
    "    print(f\"  {name}: {param.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using Built-in Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PyTorch provides optimized implementations\n",
    "linear = nn.Linear(10, 5)  # Same as our SimpleLinear\n",
    "\n",
    "x = torch.randn(32, 10)\n",
    "output = linear(x)\n",
    "\n",
    "print(f\"Output shape: {output.shape}\")\n",
    "print(f\"\\nBuilt-in Linear layer parameters:\")\n",
    "for name, param in linear.named_parameters():\n",
    "    print(f\"  {name}: {param.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building a Multi-Layer Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleNet(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
    "        super().__init__()\n",
    "        self.layer1 = nn.Linear(input_dim, hidden_dim)\n",
    "        self.layer2 = nn.Linear(hidden_dim, output_dim)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # x: (batch_size, input_dim)\n",
    "        x = self.layer1(x)  # (batch_size, hidden_dim)\n",
    "        x = F.relu(x)       # Activation function\n",
    "        x = self.layer2(x)  # (batch_size, output_dim)\n",
    "        return x\n",
    "\n",
    "# Create and test\n",
    "model = SimpleNet(input_dim=20, hidden_dim=64, output_dim=10)\n",
    "x = torch.randn(16, 20)\n",
    "output = model(x)\n",
    "\n",
    "print(f\"Input shape: {x.shape}\")\n",
    "print(f\"Output shape: {output.shape}\")\n",
    "print(f\"\\nAll parameters:\")\n",
    "for name, param in model.named_parameters():\n",
    "    print(f\"  {name}: {param.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Forward and Backward Passes\n",
    "\n",
    "The training loop consists of:\n",
    "1. Forward pass (compute predictions)\n",
    "2. Compute loss\n",
    "3. Backward pass (compute gradients)\n",
    "4. Update parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a simple model\n",
    "model = nn.Linear(10, 1)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.01)\n",
    "\n",
    "# Dummy data\n",
    "x = torch.randn(32, 10)\n",
    "y_true = torch.randn(32, 1)\n",
    "\n",
    "print(\"Training for 5 iterations:\\n\")\n",
    "\n",
    "for i in range(5):\n",
    "    # 1. Forward pass\n",
    "    y_pred = model(x)\n",
    "    \n",
    "    # 2. Compute loss\n",
    "    loss = F.mse_loss(y_pred, y_true)\n",
    "    \n",
    "    # 3. Backward pass\n",
    "    optimizer.zero_grad()  # Clear previous gradients\n",
    "    loss.backward()        # Compute gradients\n",
    "    \n",
    "    # 4. Update parameters\n",
    "    optimizer.step()\n",
    "    \n",
    "    print(f\"Iteration {i+1}: Loss = {loss.item():.6f}\")\n",
    "\n",
    "print(\"\\n✓ Loss should decrease over iterations\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Essential Operations for Transformers\n",
    "\n",
    "Let's put it all together with operations you'll use constantly in transformer code."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Softmax\n",
    "\n",
    "Critical for attention weights!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Softmax converts scores to probabilities\n",
    "scores = torch.randn(2, 4, 4)  # (batch, seq_len, seq_len)\n",
    "\n",
    "# Apply softmax over last dimension (keys)\n",
    "attention = F.softmax(scores, dim=-1)\n",
    "\n",
    "print(f\"Scores shape: {scores.shape}\")\n",
    "print(f\"Attention shape: {attention.shape}\")\n",
    "\n",
    "# Verify: sum over last dimension should be 1\n",
    "sums = attention.sum(dim=-1)\n",
    "print(f\"\\nSum over last dim (should be all 1.0):\")\n",
    "print(sums[0])  # First batch\n",
    "\n",
    "# All values should be between 0 and 1\n",
    "print(f\"\\nMin value: {attention.min().item():.6f}\")\n",
    "print(f\"Max value: {attention.max().item():.6f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Masking\n",
    "\n",
    "Causal masking prevents attending to future tokens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create causal mask (lower triangular)\n",
    "seq_len = 5\n",
    "mask = torch.tril(torch.ones(seq_len, seq_len))\n",
    "\n",
    "print(\"Causal mask (1 = allowed, 0 = blocked):\")\n",
    "print(mask)\n",
    "\n",
    "# Apply mask to attention scores\n",
    "scores = torch.randn(1, seq_len, seq_len)\n",
    "print(f\"\\nOriginal scores:\\n{scores[0]}\")\n",
    "\n",
    "# Mask out future positions by setting to -inf\n",
    "scores_masked = scores.masked_fill(mask == 0, float('-inf'))\n",
    "print(f\"\\nMasked scores (-inf prevents attention):\\n{scores_masked[0]}\")\n",
    "\n",
    "# After softmax, -inf becomes 0\n",
    "attention = F.softmax(scores_masked, dim=-1)\n",
    "print(f\"\\nAttention weights (future positions are 0):\\n{attention[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dropout\n",
    "\n",
    "Regularization technique used throughout transformers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropout randomly zeros elements during training\n",
    "x = torch.ones(4, 4)\n",
    "dropout = nn.Dropout(p=0.5)  # Drop 50% of elements\n",
    "\n",
    "# Training mode\n",
    "dropout.train()\n",
    "x_dropped = dropout(x)\n",
    "\n",
    "print(\"Original tensor (all ones):\")\n",
    "print(x)\n",
    "print(\"\\nAfter dropout (training mode):\")\n",
    "print(x_dropped)\n",
    "print(\"Note: Remaining values are scaled up (× 2) to maintain expected sum\")\n",
    "\n",
    "# Evaluation mode (no dropout)\n",
    "dropout.eval()\n",
    "x_eval = dropout(x)\n",
    "print(\"\\nAfter dropout (eval mode):\")\n",
    "print(x_eval)\n",
    "print(\"No dropout in eval mode ✓\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Layer Normalization\n",
    "\n",
    "Stabilizes training in transformers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Layer normalization normalizes across features\n",
    "batch_size = 2\n",
    "seq_len = 3\n",
    "d_model = 4\n",
    "\n",
    "x = torch.randn(batch_size, seq_len, d_model)\n",
    "layer_norm = nn.LayerNorm(d_model)\n",
    "\n",
    "x_normalized = layer_norm(x)\n",
    "\n",
    "print(f\"Input shape: {x.shape}\")\n",
    "print(f\"Output shape: {x_normalized.shape}\")\n",
    "\n",
    "# Check normalization (mean ≈ 0, std ≈ 1 over last dimension)\n",
    "print(f\"\\nPer-position statistics:\")\n",
    "print(f\"Mean (should be ~0): {x_normalized[0, 0].mean().item():.6f}\")\n",
    "print(f\"Std (should be ~1): {x_normalized[0, 0].std(unbiased=False).item():.6f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Putting It All Together: Mini Attention\n",
    "\n",
    "Let's implement a minimal attention mechanism to tie everything together!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simple_attention(Q, K, V):\n",
    "    \"\"\"\n",
    "    Simplified attention mechanism.\n",
    "    \n",
    "    Args:\n",
    "        Q: Query (batch, seq_len, d_k)\n",
    "        K: Key (batch, seq_len, d_k)\n",
    "        V: Value (batch, seq_len, d_v)\n",
    "    \n",
    "    Returns:\n",
    "        output: (batch, seq_len, d_v)\n",
    "        attention: (batch, seq_len, seq_len)\n",
    "    \"\"\"\n",
    "    # 1. Compute attention scores: Q @ K^T\n",
    "    d_k = Q.size(-1)\n",
    "    scores = Q @ K.transpose(-2, -1)  # (batch, seq_len, seq_len)\n",
    "    \n",
    "    # 2. Scale\n",
    "    scores = scores / math.sqrt(d_k)\n",
    "    \n",
    "    # 3. Softmax to get attention weights\n",
    "    attention = F.softmax(scores, dim=-1)  # (batch, seq_len, seq_len)\n",
    "    \n",
    "    # 4. Apply attention to values\n",
    "    output = attention @ V  # (batch, seq_len, d_v)\n",
    "    \n",
    "    return output, attention\n",
    "\n",
    "# Test it!\n",
    "batch_size = 2\n",
    "seq_len = 4\n",
    "d_k = 8\n",
    "\n",
    "Q = torch.randn(batch_size, seq_len, d_k)\n",
    "K = torch.randn(batch_size, seq_len, d_k)\n",
    "V = torch.randn(batch_size, seq_len, d_k)\n",
    "\n",
    "output, attention = simple_attention(Q, K, V)\n",
    "\n",
    "print(f\"Q shape: {Q.shape}\")\n",
    "print(f\"K shape: {K.shape}\")\n",
    "print(f\"V shape: {V.shape}\")\n",
    "print(f\"\\nOutput shape: {output.shape}\")\n",
    "print(f\"Attention shape: {attention.shape}\")\n",
    "\n",
    "# Verify attention weights sum to 1\n",
    "print(f\"\\nAttention weights sum: {attention[0, 0].sum().item():.6f}\")\n",
    "print(\"\\n✓ You just implemented attention! This is the core of transformers!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quick Quiz\n",
    "\n",
    "Test your understanding:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Question 1: What's the output shape?\n",
    "A = torch.randn(32, 128, 512)  # (batch, seq_len, d_model)\n",
    "W = torch.randn(512, 256)       # (d_model, d_out)\n",
    "result = A @ W\n",
    "print(f\"Q1: Shape of A @ W is: {result.shape}\")\n",
    "print(\"Expected: (32, 128, 256)\\n\")\n",
    "\n",
    "# Question 2: What does transpose do?\n",
    "B = torch.randn(32, 128, 64)\n",
    "B_T = B.transpose(-2, -1)\n",
    "print(f\"Q2: Shape after transpose(-2, -1): {B_T.shape}\")\n",
    "print(\"Expected: (32, 64, 128)\\n\")\n",
    "\n",
    "# Question 3: Softmax output properties\n",
    "scores = torch.randn(32, 128, 128)\n",
    "probs = F.softmax(scores, dim=-1)\n",
    "print(f\"Q3: Sum of probabilities (dim=-1): {probs[0, 0].sum().item():.6f}\")\n",
    "print(\"Expected: 1.000000\\n\")\n",
    "\n",
    "print(\"✓ If all answers match, you're ready for Module 01!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "You now know:\n",
    "\n",
    "✓ Creating and manipulating tensors  \n",
    "✓ Broadcasting and shape operations  \n",
    "✓ Matrix multiplication (`@`)  \n",
    "✓ Autograd for automatic differentiation  \n",
    "✓ Building modules with `nn.Module`  \n",
    "✓ Forward/backward passes  \n",
    "✓ Essential operations: softmax, masking, dropout, layer norm  \n",
    "✓ **You implemented attention from scratch!**  \n",
    "\n",
    "## Next Steps\n",
    "\n",
    "1. Review any sections you found challenging\n",
    "2. Try modifying the simple attention code\n",
    "3. Proceed to Module 01 where we'll build proper attention with all the bells and whistles!\n",
    "\n",
    "**You're ready to build transformers!**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
